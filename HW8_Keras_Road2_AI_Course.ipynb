{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNbFxVzwUzgwPReK1ei2yt8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielturg/Road2_AI_Course_Scripts/blob/main/HW8_Keras_Road2_AI_Course.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHtrzIrIHsZ6",
        "outputId": "0a413509-f225-4639-fd11-f1f6e28d185e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-30 14:59:39--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.1.207, 172.217.214.207, 142.251.6.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.1.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/content/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/content/cats_and_d 100%[===================>]  65.43M   236MB/s    in 0.3s    \n",
            "\n",
            "2023-12-30 14:59:39 (236 MB/s) - ‘/content/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               6422784   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21137729 (80.63 MB)\n",
            "Trainable params: 6423041 (24.50 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Epoch 1/5\n",
            "62/62 [==============================] - 42s 520ms/step - loss: 0.5284 - accuracy: 0.8115 - val_loss: 0.2503 - val_accuracy: 0.9042\n",
            "Epoch 2/5\n",
            "62/62 [==============================] - 32s 511ms/step - loss: 0.2606 - accuracy: 0.9014 - val_loss: 0.2613 - val_accuracy: 0.9103\n",
            "Epoch 3/5\n",
            "62/62 [==============================] - 30s 487ms/step - loss: 0.1771 - accuracy: 0.9319 - val_loss: 0.3067 - val_accuracy: 0.8901\n",
            "Epoch 4/5\n",
            "62/62 [==============================] - 32s 522ms/step - loss: 0.1769 - accuracy: 0.9345 - val_loss: 0.2506 - val_accuracy: 0.9123\n",
            "Epoch 5/5\n",
            "62/62 [==============================] - 32s 509ms/step - loss: 0.2212 - accuracy: 0.9228 - val_loss: 0.2826 - val_accuracy: 0.9062\n",
            "Final Accuracy: 0.922764241695404\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Download and extract the dataset\n",
        "zip_path = '/content/cats_and_dogs_filtered.zip'\n",
        "!wget --no-check-certificate \\\n",
        "    'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip' \\\n",
        "    -O $zip_path\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')\n",
        "\n",
        "# Define paths\n",
        "base_dir = '/content/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Load the VGG16 model pre-trained on ImageNet\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Create a new model with VGG16 base and additional layers\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "\n",
        "# Freeze all layers except the last convolutional layer\n",
        "for layer in base_model.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom fully connected layers for classification\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Binary classification (cats vs dogs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Data Augmentation and Loading Dataset\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(224, 224),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size=(224, 224),\n",
        "                                                        batch_size=32,\n",
        "                                                        class_mode='binary')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "                    epochs=5,  # You can adjust the number of epochs\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=validation_generator.samples // validation_generator.batch_size)\n",
        "\n",
        "# Display the final accuracy\n",
        "print(\"Final Accuracy:\", history.history['accuracy'][-1])\n"
      ]
    }
  ]
}