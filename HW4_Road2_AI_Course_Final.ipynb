{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1xQlA2mMrIWZY-ul-ulEhW4tvqTP4A1jV",
      "authorship_tag": "ABX9TyOIkYotnHthBiMQKAJVCBzZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielturg/Road2_AI_Course_Scripts/blob/main/HW4_Road2_AI_Course_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessig the images into a folder called 0"
      ],
      "metadata": {
        "id": "Rm2c83ZBO6EM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcgF9nQGJJBw",
        "outputId": "06b54382-f785-4604-f20d-b72949cff692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image processing completed.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def crop_resize_grayscale(input_folder, output_folder):\n",
        "    # Create the output folder\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Get a list of image files in the input folder\n",
        "    image_files = [file for file in os.listdir(input_folder) if file.endswith(\".jpg\")]\n",
        "\n",
        "    # Process each image file\n",
        "    for image_file in image_files:\n",
        "        # Load the image\n",
        "        image_path = os.path.join(input_folder, image_file)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Load the label\n",
        "        label_path = os.path.join(input_folder, image_file.replace('.jpg', '.txt'))\n",
        "        label_values = open(label_path).readline().split()\n",
        "\n",
        "        # Extract bounding box values from the label\n",
        "        contains_drone = int(label_values[0])\n",
        "        x_center, y_center, width, height = map(float, label_values[1:])\n",
        "\n",
        "        # Compute bounding box coordinates\n",
        "        xmin = int(max(0, (x_center - 0.5 * width) * image.shape[1]))\n",
        "        ymin = int(max(0, (y_center - 0.5 * height) * image.shape[0]))\n",
        "        xmax = int(min(image.shape[1], (x_center + 0.5 * width) * image.shape[1]))\n",
        "        ymax = int(min(image.shape[0], (y_center + 0.5 * height) * image.shape[0]))\n",
        "\n",
        "        # Crop and resize the image\n",
        "        cropped_image = image[ymin:ymax, xmin:xmax]\n",
        "        resized_image = cv2.resize(cropped_image, (28, 28))\n",
        "\n",
        "        # Convert the image to grayscale\n",
        "        grayscale_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Save the processed image\n",
        "        output_image_path = os.path.join(output_folder, image_file)\n",
        "        cv2.imwrite(output_image_path, grayscale_image)\n",
        "\n",
        "        # Save the corresponding label\n",
        "        output_label_path = os.path.join(output_folder, image_file.replace('.jpg', '.txt'))\n",
        "        with open(output_label_path, 'w') as label_file:\n",
        "            label_file.write(str(contains_drone))\n",
        "\n",
        "# Example usage\n",
        "input_folder = \"/content/drive/MyDrive/AI_Course/drone_data\"\n",
        "output_folder = \"/content/drive/MyDrive/AI_Course/Processed_Dataset/0\"\n",
        "crop_resize_grayscale(input_folder, output_folder)\n",
        "\n",
        "print(\"Image processing completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing the images with fake bounding boxes into a folder called \"1\""
      ],
      "metadata": {
        "id": "8GaPdlhaPCmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def generate_fake_labels(image_shape):\n",
        "    # Generate random bounding box values\n",
        "    x_center = np.random.uniform(0.2, 0.8)\n",
        "    y_center = np.random.uniform(0.2, 0.8)\n",
        "    width = np.random.uniform(0.2, 0.4)\n",
        "    height = np.random.uniform(0.2, 0.4)\n",
        "\n",
        "    # Compute bounding box coordinates\n",
        "    xmin = int(max(0, (x_center - 0.5 * width) * image_shape[1]))\n",
        "    ymin = int(max(0, (y_center - 0.5 * height) * image_shape[0]))\n",
        "    xmax = int(min(image_shape[1], (x_center + 0.5 * width) * image_shape[1]))\n",
        "    ymax = int(min(image_shape[0], (y_center + 0.5 * height) * image_shape[0]))\n",
        "\n",
        "    return xmin, ymin, xmax, ymax\n",
        "\n",
        "def crop_resize_grayscale_fake(input_folder, output_folder):\n",
        "    # Create the output folder\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Get a list of image files in the input folder\n",
        "    image_files = [file for file in os.listdir(input_folder) if file.endswith(\".jpg\")]\n",
        "\n",
        "    # Process each image file\n",
        "    for image_file in image_files:\n",
        "        # Load the image\n",
        "        image_path = os.path.join(input_folder, image_file)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Generate fake label values\n",
        "        xmin, ymin, xmax, ymax = generate_fake_labels(image.shape)\n",
        "\n",
        "        # Crop and resize the image\n",
        "        cropped_image = image[ymin:ymax, xmin:xmax]\n",
        "        resized_image = cv2.resize(cropped_image, (28, 28))\n",
        "\n",
        "        # Convert the image to grayscale\n",
        "        grayscale_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Save the processed image with \"_fake\" suffix\n",
        "        output_image_path = os.path.join(output_folder, image_file.replace('.jpg', '_fake.jpg'))\n",
        "        cv2.imwrite(output_image_path, grayscale_image)\n",
        "\n",
        "        # Save the corresponding fake label with \"_fake\" suffix\n",
        "        output_label_path = os.path.join(output_folder, image_file.replace('.jpg', '_fake.txt'))\n",
        "        with open(output_label_path, 'w') as label_file:\n",
        "            label_file.write(\"1\")  # Assuming the label for fake images is always 1\n",
        "\n",
        "# Example usage\n",
        "input_folder = \"/content/drive/MyDrive/AI_Course/drone_data\"\n",
        "output_folder = \"/content/drive/MyDrive/AI_Course/Processed_Dataset/1\"\n",
        "crop_resize_grayscale_fake(input_folder, output_folder)\n",
        "\n",
        "print(\"Fake image processing completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDj1dlC0PKin",
        "outputId": "89b3c153-b969-42b6-8e94-932a4d9a0a65"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fake image processing completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "splitting the dataset into train and test"
      ],
      "metadata": {
        "id": "cCUctRAYUYzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "def split_data(input_folder, output_folder, train_ratio=0.8):\n",
        "    # Create output folders\n",
        "    train_folder = os.path.join(output_folder, 'train')\n",
        "    test_folder = os.path.join(output_folder, 'test')\n",
        "    os.makedirs(train_folder, exist_ok=True)\n",
        "    os.makedirs(test_folder, exist_ok=True)\n",
        "\n",
        "    # Get a list of image files in the input folder\n",
        "    image_files_0 = [file for file in os.listdir(os.path.join(input_folder, '0')) if file.endswith(\".jpg\")]\n",
        "    image_files_1 = [file for file in os.listdir(os.path.join(input_folder, '1')) if file.endswith(\"_fake.jpg\")]\n",
        "\n",
        "    # Shuffle the data\n",
        "    random.shuffle(image_files_0)\n",
        "    random.shuffle(image_files_1)\n",
        "\n",
        "    # Determine the number of files for training and testing\n",
        "    num_train_0 = int(len(image_files_0) * train_ratio)\n",
        "    num_test_0 = len(image_files_0) - num_train_0\n",
        "    num_train_1 = int(len(image_files_1) * train_ratio)\n",
        "    num_test_1 = len(image_files_1) - num_train_1\n",
        "\n",
        "    # Copy 80% of the data from \"0\" and \"1\" to the \"train\" folder\n",
        "    for image_file in image_files_0[:num_train_0]:\n",
        "        shutil.copy(os.path.join(input_folder, '0', image_file), os.path.join(train_folder, image_file))\n",
        "        shutil.copy(os.path.join(input_folder, '0', image_file.replace('.jpg', '.txt')),\n",
        "                    os.path.join(train_folder, image_file.replace('.jpg', '.txt')))\n",
        "\n",
        "    for image_file in image_files_1[:num_train_1]:\n",
        "        shutil.copy(os.path.join(input_folder, '1', image_file), os.path.join(train_folder, image_file))\n",
        "        shutil.copy(os.path.join(input_folder, '1', image_file.replace('_fake.jpg', '_fake.txt')),\n",
        "                    os.path.join(train_folder, image_file.replace('_fake.jpg', '_fake.txt')))\n",
        "\n",
        "    # Copy 20% of the data from \"0\" and \"1\" to the \"test\" folder\n",
        "    for image_file in image_files_0[-num_test_0:]:\n",
        "        shutil.copy(os.path.join(input_folder, '0', image_file), os.path.join(test_folder, image_file))\n",
        "        shutil.copy(os.path.join(input_folder, '0', image_file.replace('.jpg', '.txt')),\n",
        "                    os.path.join(test_folder, image_file.replace('.jpg', '.txt')))\n",
        "\n",
        "    for image_file in image_files_1[-num_test_1:]:\n",
        "        shutil.copy(os.path.join(input_folder, '1', image_file), os.path.join(test_folder, image_file))\n",
        "        shutil.copy(os.path.join(input_folder, '1', image_file.replace('_fake.jpg', '_fake.txt')),\n",
        "                    os.path.join(test_folder, image_file.replace('_fake.jpg', '_fake.txt')))\n",
        "\n",
        "# Example usage\n",
        "input_folder = \"/content/drive/MyDrive/AI_Course/Processed_Dataset\"\n",
        "output_folder = \"/content/drive/MyDrive/AI_Course/Processed_Dataset\"\n",
        "split_data(input_folder, output_folder)\n",
        "\n",
        "print(\"Data splitting completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNSd9bWOUcIv",
        "outputId": "d28ec7b4-544f-4dc4-ba48-8012e5142841"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data splitting completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "building and training the model- loading data and libraries"
      ],
      "metadata": {
        "id": "8rzfYAQTuSQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_data(folder_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    image_files = [file for file in os.listdir(folder_path) if file.endswith(\".jpg\")]\n",
        "    for image_file in image_files:\n",
        "        # Load and preprocess the image\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        image = load_img(image_path, color_mode='grayscale', target_size=(28, 28))\n",
        "        image_array = img_to_array(image) / 255.0  # Normalize pixel values to be between 0 and 1\n",
        "        images.append(image_array)\n",
        "\n",
        "        # Load and preprocess the label\n",
        "        label_path = os.path.join(folder_path, image_file.replace('.jpg', '.txt'))\n",
        "        label = int(open(label_path).readline().strip())\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load the data\n",
        "train_folder = \"/content/drive/MyDrive/AI_Course/Processed_Dataset/train\"\n",
        "test_folder = \"/content/drive/MyDrive/AI_Course/Processed_Dataset/test\"\n",
        "\n",
        "X_train, y_train = load_data(train_folder)\n",
        "X_val, y_val = load_data(test_folder)  # Use \"test\" folder as validation set\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qMwfn-4IuVBB",
        "outputId": "7e17da4f-6850-4757-ff7e-6fb8f493d510"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e0dbb48b9bab>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nEpoch {epoch + 1}/{epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1127, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5575, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 2) and (None, 1) are incompatible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import BinaryAccuracy"
      ],
      "metadata": {
        "id": "SHWGlmjoyp2E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "building and training the network"
      ],
      "metadata": {
        "id": "3e3IvTJDw8ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the neural network model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28, 1)),\n",
        "    Dense(1, activation='sigmoid')  # Change activation to 'sigmoid' for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.01),\n",
        "    loss=BinaryCrossentropy(),\n",
        "    metrics=[BinaryAccuracy()]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=1,\n",
        "        batch_size=batch_size,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "    print(f\"Validation Accuracy: {val_accuracy}\")\n",
        "\n",
        "print(\"Training completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7NQd7t3wuI4",
        "outputId": "b5cc13b5-0e65-4cd1-cc6d-70875790abd9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n",
            "204/204 [==============================] - 6s 5ms/step - loss: 0.5237 - binary_accuracy: 0.7786 - val_loss: 0.4352 - val_binary_accuracy: 0.8563\n",
            "Validation Accuracy: 0.8562653660774231\n",
            "\n",
            "Epoch 2/10\n",
            "204/204 [==============================] - 1s 6ms/step - loss: 0.4403 - binary_accuracy: 0.8303 - val_loss: 0.4827 - val_binary_accuracy: 0.6708\n",
            "Validation Accuracy: 0.6707616448402405\n",
            "\n",
            "Epoch 3/10\n",
            "204/204 [==============================] - 1s 5ms/step - loss: 0.4294 - binary_accuracy: 0.8332 - val_loss: 0.3640 - val_binary_accuracy: 0.8692\n",
            "Validation Accuracy: 0.8691646456718445\n",
            "\n",
            "Epoch 4/10\n",
            "204/204 [==============================] - 1s 5ms/step - loss: 0.4119 - binary_accuracy: 0.8401 - val_loss: 0.5208 - val_binary_accuracy: 0.5958\n",
            "Validation Accuracy: 0.5958231091499329\n",
            "\n",
            "Epoch 5/10\n",
            "204/204 [==============================] - 1s 5ms/step - loss: 0.3985 - binary_accuracy: 0.8509 - val_loss: 0.4746 - val_binary_accuracy: 0.7015\n",
            "Validation Accuracy: 0.7014741897583008\n",
            "\n",
            "Epoch 6/10\n",
            "204/204 [==============================] - 1s 4ms/step - loss: 0.4177 - binary_accuracy: 0.8409 - val_loss: 0.3882 - val_binary_accuracy: 0.8864\n",
            "Validation Accuracy: 0.8863636255264282\n",
            "\n",
            "Epoch 7/10\n",
            "204/204 [==============================] - 1s 4ms/step - loss: 0.3959 - binary_accuracy: 0.8641 - val_loss: 0.4625 - val_binary_accuracy: 0.7666\n",
            "Validation Accuracy: 0.7665847539901733\n",
            "\n",
            "Epoch 8/10\n",
            "204/204 [==============================] - 1s 4ms/step - loss: 0.3845 - binary_accuracy: 0.8629 - val_loss: 0.4448 - val_binary_accuracy: 0.8378\n",
            "Validation Accuracy: 0.837837815284729\n",
            "\n",
            "Epoch 9/10\n",
            "204/204 [==============================] - 1s 4ms/step - loss: 0.3869 - binary_accuracy: 0.8667 - val_loss: 0.3451 - val_binary_accuracy: 0.8950\n",
            "Validation Accuracy: 0.8949631452560425\n",
            "\n",
            "Epoch 10/10\n",
            "204/204 [==============================] - 1s 4ms/step - loss: 0.3951 - binary_accuracy: 0.8490 - val_loss: 0.3432 - val_binary_accuracy: 0.8950\n",
            "Validation Accuracy: 0.8949631452560425\n",
            "Training completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "predicting:"
      ],
      "metadata": {
        "id": "rpNdnpMNzxnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "\n",
        "# Path to the image you want to predict\n",
        "path_to_image = \"/content/drive/MyDrive/AI_Course/Detect-a-Drone-in-the-Skysss.jpg\"\n",
        "\n",
        "# Load and preprocess the image\n",
        "img = load_img(path_to_image, color_mode='grayscale', target_size=(28, 28))\n",
        "img_array = img_to_array(img) / 255.0  # Normalize pixel values to be between 0 and 1\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "# Make a prediction using the trained model\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "# Convert the prediction to a human-readable label\n",
        "class_label = \"Drone\" if prediction[0][0] < 0.5 else \"No Drone\"\n",
        "\n",
        "print(f\"The model predicts: {class_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udk6AH1pzzzK",
        "outputId": "a97239f5-6d7c-4e2c-f827-9b57536f0ee7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 41ms/step\n",
            "The model predicts: No Drone\n"
          ]
        }
      ]
    }
  ]
}